name: Sync Rules Files

on:
  push:
    paths:
      - rules-list.txt
  schedule:
    - cron: '0 4 * * *'
  workflow_dispatch:

env:
  RULES_LIST: rules-list.txt
  MAPPING_FILE: mapping.csv
  TEMP_MAPPING_FILE: temp_mapping.csv
  DEL_LIST_FILE: del_list.txt
  OUTPUT_DIR: rules

jobs:
  sync-rules:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install Python dependencies
      run: pip install requests

    - name: Create output directory if not exists
      run: mkdir -p ${{ env.OUTPUT_DIR }}

    - name: Process rules-list.txt and update mapping.csv with Python
      id: process_rules
      run: |
        python3 << 'EOF'
        import csv
        import os
        import requests
        import hashlib
        from urllib.parse import urlparse

        rules_list_path = "${{ env.RULES_LIST }}"
        mapping_file_path = "${{ env.MAPPING_FILE }}"
        temp_mapping_file_path = "${{ env.TEMP_MAPPING_FILE }}"
        del_list_file_path = "${{ env.DEL_LIST_FILE }}"
        output_dir = "${{ env.OUTPUT_DIR }}"

        def calculate_hash(file_path):
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()

        # Read existing mappings from CSV
        existing_mappings = {}
        if os.path.isfile(mapping_file_path):
            with open(mapping_file_path, mode='r', newline='') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    existing_mappings[row['URL']] = row

        # Read URLs from rules-list.txt
        new_urls = set()
        with open(rules_list_path, mode='r') as file:
            for line in file:
                url = line.strip()
                if url.startswith(('http://', 'https://')):
                    new_urls.add(url)

        # Create header if temp_mapping_file does not exist
        if not os.path.isfile(temp_mapping_file_path):
            with open(temp_mapping_file_path, mode='w', newline='') as file:
                writer = csv.writer(file)
                writer.writerow(['URL', 'Remote_Filename', 'Local_Filename', 'Hash'])

        # Compare and update temp_mapping.csv
        with open(temp_mapping_file_path, mode='a', newline='') as temp_file:
            writer = csv.writer(temp_file)
            filename_count = {}

            for url in new_urls:
                response = requests.head(url, allow_redirects=True)
                remote_filename = os.path.basename(url)
                local_filename = remote_filename

                # Count occurrences of each remote_filename
                if remote_filename in filename_count:
                    filename_count[remote_filename] += 1
                else:
                    filename_count[remote_filename] = 1

                # Adjust local_filename if conflict exists
                if filename_count[remote_filename] > 1:
                    parsed_url = urlparse(url)
                    last_segment = parsed_url.path.split('/')[-2]
                    local_filename = f"{last_segment}-{remote_filename}"

                # Calculate hash for existing file if it exists
                local_file_path = os.path.join(output_dir, local_filename)
                existing_hash = None
                if os.path.isfile(local_file_path):
                    existing_hash = calculate_hash(local_file_path)

                # Fetch remote hash
                response = requests.get(url, stream=True)
                remote_hash = hashlib.md5(response.content).hexdigest()

                # Write to temp_mapping.csv if there's a change or no existing entry
                if url not in existing_mappings or existing_mappings[url]['Hash'] != remote_hash:
                    writer.writerow([url, remote_filename, local_filename, remote_hash])
                else:
                    writer.writerow(existing_mappings[url].values())

            # Identify files to delete
            del_list = []
            for url in existing_mappings:
                if url not in new_urls:
                    del_list.append(existing_mappings[url]['Local_Filename'])

            # Write del_list to file
            with open(del_list_file_path, mode='w') as del_file:
                for filename in del_list:
                    del_file.write(f"{filename}\n")
        EOF

    - name: Download updated files based on temp_mapping.csv
      run: |
        if [ -f "${{ env.TEMP_MAPPING_FILE }}" ]; then
          while IFS=',' read -r url remote_filename local_filename hash; do
            local_file="${{ env.OUTPUT_DIR }}/${local_filename}"
            if ! test -f "$local_file" || [ "$(md5sum $local_file | awk '{ print $1 }')" != "$hash" ]; then
              wget --continue -O "$local_file" "$url" || echo "Failed to download $url. Skipping."
            fi
          done < <(tail -n +2 "${{ env.TEMP_MAPPING_FILE }}")
        else
          echo "No new or updated files to download."
        fi

    - name: Delete obsolete files based on del_list.txt
      run: |
        if [ -f "${{ env.DEL_LIST_FILE }}" ]; then
          while IFS= read -r filename; do
            rm -f "${{ env.OUTPUT_DIR }}/$filename" || echo "Failed to delete $filename. Skipping."
          done < "${{ env.DEL_LIST_FILE }}"
        else
          echo "No obsolete files to delete."
        fi

    - name: Update mapping.csv
      run: |
        cp "${{ env.TEMP_MAPPING_FILE }}" "${{ env.MAPPING_FILE }}"
        rm "${{ env.TEMP_MAPPING_FILE }}"
        rm "${{ env.DEL_LIST_FILE }}"

    - name: List files in rules directory
      run: ls -la "${{ env.OUTPUT_DIR }}"

    - name: Add changes to staging
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add "${{ env.OUTPUT_DIR }}"
        git add "${{ env.MAPPING_FILE }}"

    - name: Commit changes
      run: |
        git diff-index --quiet HEAD || git commit -m "Update rules files from rules-list.txt"

    - name: Push changes
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
