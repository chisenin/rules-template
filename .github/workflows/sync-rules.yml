name: Sync Rules Files

on:
  push:
    paths:
      - rules-list.txt
      - mapping.csv
  schedule:
    - cron: '0 4 * * *'
  workflow_dispatch:

env:
  RULES_LIST: rules-list.txt
  MAPPING_FILE: mapping.csv
  OUTPUT_DIR: rules

jobs:
  sync-rules:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install Python dependencies
      run: pip install requests

    - name: Create output directory if not exists
      run: mkdir -p ${{ env.OUTPUT_DIR }}

    - name: Validate rules-list.txt exists with valid URLs
      run: |
        if [ ! -f "${{ env.RULES_LIST }}" ]; then
          echo "Error: ${RULES_LIST} file does not exist."
          exit 1
        fi
        valid_rules=$(grep -E '^https?://' "${{ env.RULES_LIST }}" | wc -l)
        if [ "$valid_rules" -eq 0 ]; then
          echo "Error: ${RULES_LIST} contains no valid URLs."
          exit 1
        fi

    - name: Process rules-list.txt and update mapping.csv with Python
      id: process_rules
      run: |
        python3 << 'EOF'
        import csv
        import os
        import requests
        from datetime import datetime

        rules_list_path = "${{ env.RULES_LIST }}"
        mapping_file_path = "${{ env.MAPPING_FILE }}"
        output_dir = "${{ env.OUTPUT_DIR }}"

        # Log paths for debugging
        print(f"Rules list path: {rules_list_path}")
        print(f"Mapping file path: {mapping_file_path}")

        # Check if mapping file exists and create header if not
        if not os.path.isfile(mapping_file_path):
            print(f"Mapping file {mapping_file_path} does not exist, creating new one.")
            with open(mapping_file_path, mode='w', newline='') as file:
                writer = csv.writer(file)
                writer.writerow(['URL', 'Remote_Filename', 'Local_Filename', 'Last_Modified'])

        # Read existing mappings from CSV
        existing_mappings = {}
        with open(mapping_file_path, mode='r', newline='') as file:
            reader = csv.DictReader(file)
            for row in reader:
                existing_mappings[row['URL']] = row

        # Read URLs and last modified times from rules-list.txt
        new_mappings = {}
        with open(rules_list_path, mode='r') as file:
            for line in file:
                url = line.strip()
                if url.startswith(('http://', 'https://')):
                    response = requests.head(url, allow_redirects=True)
                    remote_filename = os.path.basename(url)
                    last_modified = response.headers.get('last-modified', 'Unknown')
                    last_modified_time = datetime.strptime(last_modified, '%a, %d %b %Y %H:%M:%S %Z') if last_modified != 'Unknown' else None
                    
                    # Add to new_mappings if not in existing or different last modified time
                    if url not in existing_mappings or existing_mappings[url]['Last_Modified'] != str(last_modified_time):
                        new_mappings[url] = {'Remote_Filename': remote_filename, 'Last_Modified': str(last_modified_time)}

        # Handle file name conflicts
        filename_count = {}
        for url, info in new_mappings.items():
            remote_filename = info['Remote_Filename']
            local_filename = remote_filename
            
            # Count occurrences of each local filename
            if local_filename in filename_count:
                filename_count[local_filename] += 1
            else:
                filename_count[local_filename] = 1
            
        # Adjust local filenames if conflicts exist
        for url, info in new_mappings.items():
            remote_filename = info['Remote_Filename']
            local_filename = remote_filename
            if filename_count[remote_filename] > 1:
                # Extract the last path segment from URL
                url_segments = url.split('/')
                last_segment = url_segments[-2]
                local_filename = f"{last_segment}-{remote_filename}"
                filename_count[local_filename] = 1  # Mark as handled
            
            # Assign the new local filename
            new_mappings[url]['Local_Filename'] = local_filename

        # Merge new mappings into existing mappings
        for url, info in new_mappings.items():
            existing_mappings[url] = info

        # Remove entries not present in rules-list.txt
        urls_to_keep = set(new_mappings.keys())
        final_mappings = {k: v for k, v in existing_mappings.items() if k in urls_to_keep}

        # Write the updated mappings to CSV
        with open(mapping_file_path, mode='w', newline='') as file:
            fieldnames = ['URL', 'Remote_Filename', 'Local_Filename', 'Last_Modified']
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(final_mappings.values())

        with open('updated_mappings.csv', mode='w', newline='') as file:
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(new_mappings.values())

        EOF

    - name: Print updated mappings
      if: always()
      run: |
        if [ -f "updated_mappings.csv" ]; then
          echo "Updated Mappings:"
          cat updated_mappings.csv
        else
          echo "No updates found."
        fi

    - name: Download updated files based on mapping.csv
      run: |
        declare -A seen_hashes

        # Read URLs with updates from updated_mappings.csv
        if [ -f "updated_mappings.csv" ]; then
          while IFS=',' read -r url remote_filename local_filename last_modified; do
            local_file="${{ env.OUTPUT_DIR }}/${local_filename}"
            echo "Downloading $url as $local_filename"
            wget --continue -O "$local_file" "$url" || echo "Failed to download $url. Skipping."
          done < <(tail -n +2 "updated_mappings.csv")
        else
          echo "No new or updated files to download."
        fi

    - name: List files in rules directory
      run: ls -la "${{ env.OUTPUT_DIR }}"

    - name: Add changes to staging
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add "${{ env.OUTPUT_DIR }}"
        git add "${{ env.MAPPING_FILE }}"

    - name: Commit changes
      run: |
        git diff-index --quiet HEAD || git commit -m "Update rules files from rules-list.txt"

    - name: Push changes
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
