name: Sync Rules Files

on:
  push:
    paths:
      - rules-list.txt
      - mapping.csv
  schedule:
    - cron: '0 4 * * *'
  workflow_dispatch:

env:
  RULES_LIST: rules-list.txt
  OUTPUT_DIR: rules
  CSV_FILE: mapping.csv

jobs:
  sync-rules:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Create output directory if not exists
      run: mkdir -p ${{ env.OUTPUT_DIR }}

    - name: Verify rules-list.txt exists
      run: |
        if [ ! -f "${{ env.RULES_LIST }}" ]; then
          echo "Error: ${RULES_LIST} file does not exist."
          exit 1
        fi

    - name: Verify mapping.csv exists or create an empty one
      run: |
        if [ ! -f "${{ env.CSV_FILE }}" ]; then
          echo "URL,Local_Filename,Hash" > "${{ env.CSV_FILE }}"
        fi

    - name: Print contents of rules-list.txt
      run: cat "${{ env.RULES_LIST }}"

    - name: Generate or update CSV mapping list
      id: generate_or_update_csv_mapping
      run: |
        > temp_mapping.csv
        echo "URL,Local_Filename,Hash" >> temp_mapping.csv
        declare -A seen_filenames
        declare -A current_hashes

        # Read existing mappings from CSV
        tail -n +2 "${{ env.CSV_FILE }}" | while IFS=',' read -r url local_filename hash; do
          current_hashes["$url"]=$hash
          seen_filenames["$local_filename"]=$url
        done

        # Read URLs from rules-list.txt
        while IFS= read -r url; do
          # Skip empty lines or comments
          if [[ -z "$url" || "$url" == \#* ]]; then
            continue
          fi

          # Ensure the URL has the correct protocol
          if [[ ! "$url" =~ ^https?:// ]]; then
            echo "Invalid URL: $url. URLs must start with http:// or https://"
            continue
          fi

          # Extract the last two path segments from URL
          path_segments=($(dirname "$url" | tr '/' '\n'))
          last_segment="${path_segments[-1]}"
          second_last_segment="${path_segments[-2]}"
          filename=$(basename "$url")

          # Determine the final filename to use
          final_filename="$filename"
          counter=1

          # Check if the filename has been seen before
          while [[ -n "${seen_filenames[$final_filename]}" ]]; do
            # If a file with the same name exists, rename both files
            extension="${filename##*.}"
            base="${filename%.*}"
            unique_base="${second_last_segment}-${last_segment}-${base}"

            # Rename existing files
            for existing_file in "${{ env.OUTPUT_DIR }}/$base"*"$extension"; do
              if [ -f "$existing_file" ]; then
                existing_filename=$(basename "$existing_file")
                new_existing_filename="${unique_base}-${counter}.${extension}"
                mv "$existing_file" "${{ env.OUTPUT_DIR }}/$new_existing_filename"
                echo "Renamed existing file: $existing_filename -> $new_existing_filename"
                seen_filenames["$new_existing_filename"]="${seen_filenames[$existing_filename]}"
                unset seen_filenames["$existing_filename"]
                ((counter++))
              fi
            done

            # Set the new final filename
            final_filename="${unique_base}-${counter}.${extension}"
            echo "File $filename already exists. Renaming to $final_filename."
            ((counter++))
          done

          # Mark the filename as seen
          seen_filenames["$final_filename"]=$url

          # Add entry to temp_mapping.csv
          echo "$url,$final_filename,${current_hashes[$url]:-}" >> temp_mapping.csv
        done < "${{ env.RULES_LIST }}"

        # Move temp_mapping.csv to CSV_FILE
        mv temp_mapping.csv "${{ env.CSV_FILE }}"

    - name: Print CSV mapping list
      run: cat "${{ env.CSV_FILE }}"

    - name: Print URLs to be downloaded
      id: print_urls
      run: |
        echo "URLs to be downloaded:"
        tail -n +2 "${{ env.CSV_FILE }}" | while IFS=',' read -r url local_filename hash; do
          echo "URL: $url -> Local Filename: $local_filename -> Hash: $hash"
        done

    - name: Download files based on CSV mapping list
      id: download_files
      run: |
        declare -A seen_hashes

        # Read existing hashes from CSV
        tail -n +2 "${{ env.CSV_FILE }}" | while IFS=',' read -r url local_filename hash; do
          seen_hashes["$url"]=$hash
        done

        tail -n +2 "${{ env.CSV_FILE }}" | while IFS=',' read -r url local_filename hash; do
          local_file="${{ env.OUTPUT_DIR }}/${local_filename}"

          # Check if the file already exists and is up to date
          if [ -f "$local_file" ]; then
            current_hash=$(sha256sum "$local_file" | awk '{print $1}')
            expected_hash="${seen_hashes[$url]}"

            if [ "$current_hash" == "$expected_hash" ]; then
              echo "$local_filename is already up to date. Skipping download."
              continue
            fi
          fi

          echo "Downloading $url as $local_filename"
          wget --continue -O "$local_file" "$url" || echo "Failed to download $url. Skipping."

          # Calculate new hash after downloading
          if [ -f "$local_file" ]; then
            new_hash=$(sha256sum "$local_file" | awk '{print $1}')
            # Update CSV with new hash
            sed -i "s|^\($url,.*\)$|\1,$new_hash|" "${{ env.CSV_FILE }}"
          fi
        done

    - name: List files in rules directory
      run: ls -la "${{ env.OUTPUT_DIR }}"

    - name: Add changes to staging
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add "${{ env.OUTPUT_DIR }}"
        git add "${{ env.CSV_FILE }}"

    - name: Commit changes
      run: |
        git diff-index --quiet HEAD || git commit -m "Update rules files from rules-list.txt"

    - name: Push changes
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
